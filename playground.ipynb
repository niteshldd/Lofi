{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/demo/org/Scarborough.wav', '/workspace/demo/org/Sky Of More.mp3', '/workspace/demo/org/Darling, Without You.mp3', \"/workspace/demo/org/He Loves I Don't Care.mp3\", '/workspace/demo/org/晚风心里吹.mp3', '/workspace/demo/org/Apology Of Dreams.mp3', '/workspace/demo/org/Home Rhythm.mp3', \"/workspace/demo/org/Babe, We're Crazy.mp3\", '/workspace/demo/org/Best Moves.mp3', '/workspace/demo/org/Open Up To Her Tomorrow.mp3', '/workspace/demo/org/千里之外.mp3', '/workspace/demo/org/Dream Of My Home.mp3', '/workspace/demo/org/Season Of My Heart.mp3']\n",
      "['/workspace/demo/noise/增强版黑胶唱片底噪.aiff', '/workspace/demo/noise/尘封的磁带录音.wav', '/workspace/demo/noise/黑胶唱片播放底噪.wav', '/workspace/demo/noise/空白黑胶唱片播放底噪.wav', '/workspace/demo/noise/黑胶唱片噪音.flac']\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import AudioFileClip, CompositeAudioClip, concatenate_audioclips\n",
    "from glob import glob\n",
    "from math import floor\n",
    "import os\n",
    "\n",
    "org_files = list(glob('/workspace/demo/org/*'))\n",
    "noise_files = list(glob('/workspace/demo/noise/*'))\n",
    "compose_dir = '/workspace/demo/noised_comp'\n",
    "\n",
    "print(org_files)\n",
    "print(noise_files)\n",
    "\n",
    "org_clips = [AudioFileClip(f) for f in org_files]\n",
    "noise_clips = [AudioFileClip(f) for f in noise_files]\n",
    "\n",
    "max_org_dur = max([c.duration for c in org_clips])\n",
    "os.makedirs(compose_dir, exist_ok=True)\n",
    "for i in range(len(noise_clips)):\n",
    "    ns_clip = noise_clips[i]\n",
    "    loop = floor(max_org_dur / ns_clip.duration)\n",
    "    noise_clips[i] = concatenate_audioclips([ns_clip for _ in range(loop)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for org_fp, org_clip in zip(org_files, org_clips):\n",
    "    for ns_fp, ns_clip in zip(noise_files, noise_clips):\n",
    "        org_name = org_fp.split('/')[-1].split('.')[0]\n",
    "        ns_name = ns_fp.split('/')[-1].split('.')[0]\n",
    "        comp_fp = os.path.join(compose_dir, f\"{org_name}-{ns_name}.mp3\")\n",
    "        comp_clip = CompositeAudioClip([org_clip.set_start(1.5), ns_clip.subclip(0, org_clip.duration)])\n",
    "        comp_clip.write_audiofile(comp_fp, org_clip.fps, logger=None)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import subprocess\n",
    "compose_dir = '/workspace/demo/noised_comp'\n",
    "\n",
    "def low_bit(fp, bitrate):\n",
    "    lb_fp = fp[:-4] + f'-br_{bitrate}.mp3'\n",
    "    cmd = f\"ffmpeg -y -i {fp} -b:a {bitrate}k {lb_fp}\"\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "for fp in glob(compose_dir+'/*.mp3'):\n",
    "    if '-br_' in fp:\n",
    "        continue\n",
    "    low_bit(fp, 32)\n",
    "    low_bit(fp, 64)\n",
    "    low_bit(fp, 128)\n",
    "\n",
    "    # lb_fp = fp[:-4] + '-br_64.mp3'\n",
    "    # cmd = f\"ffmpeg -y -i {fp} -b:a 64k {lb_fp}\"\n",
    "    # subprocess.run(cmd, shell=True)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '001: #806805703861057941268031', 'key': 12, 'mode': 6, 'bpm': 78, 'energy': 0.491, 'valence': 0.495, 'chords': [1, 5, 4, 5, 1, 5, 4, 3, 4], 'melodies': [[1, 1, 1, 3, 3, 3, 3, 3], [3, 2, 2, 2, 2, 1, 1, 1], [1, 1, 1, 1, 1, 1, 3, 3], [5, 5, 5, 5, 5, 5, 5, 5], [5, 1, 5, 5, 5, 5, 5, 5], [5, 5, 2, 2, 2, 2, 1, 1], [1, 1, 1, 1, 1, 1, 1, 5], [5, 5, 5, 5, 5, 9, 10, 10], [10, 10, 10, 10, 10, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# convert tone.js and midi\n",
    "\n",
    "import json\n",
    "import mido\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "raw_json = json.loads(open('/workspace/output.json', 'r').read())\n",
    "params = eval(raw_json)\n",
    "print(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, pow\n",
    "import re\n",
    "from collections import namedtuple\n",
    "\n",
    "NoteLiteral = namedtuple('NoteLiteral', ['note_name', 'pitch', 'named'])\n",
    "\n",
    "\n",
    "FIFTHS = [0, 2, 4, -1, 1, 3, 5]\n",
    "STEPS_TO_OCTS = list(map(FIFTHS, lambda f: floor(f*7) / 12))\n",
    "SEMI = [0, 2, 4, 5, 7, 9, 11]\n",
    "\n",
    "\n",
    "def encode_pitch(step, alt, oct, dir=1):\n",
    "    f = FIFTHS[step] + 7 * alt\n",
    "    if oct is None:\n",
    "        return dir * f\n",
    "\n",
    "    o = oct - STEPS_TO_OCTS[step]\n",
    "    return dir * f, dir * o\n",
    "\n",
    "\n",
    "note_pat = re.compile(r\"/^([a-gA-G]?)(#{1,}|b{1,}|x{1,}|)(-?\\d*)\\s*(.*)$/\")\n",
    "\n",
    "\n",
    "def tokenize_note(note):\n",
    "    res = re.findall(note, note_pat).groups()\n",
    "    return res[1].upper(), res[2].replace('/x/g', \"##\"), res[3], res[4]\n",
    "\n",
    "\n",
    "def parse(note_name):\n",
    "    tokens = tokenize_note(note_name)\n",
    "\n",
    "    if tokens[0] == '' or tokens[3] != '':\n",
    "        return None\n",
    "\n",
    "    letter = tokens[0]\n",
    "    step = (letter.encode('unicode-escape') + 3 ) %7\n",
    "\n",
    "    acc = tokens[1]\n",
    "    oct_str = tokens[2]\n",
    "    alt = -1 * len(acc) if acc[0] == 'b' else len(acc)\n",
    "    oct = len(oct_str) if oct_str else None\n",
    "\n",
    "    coord = encode_pitch(step, alt, oct)\n",
    "    name = letter + acc + oct_str\n",
    "    pc = letter + acc\n",
    "    chroma = (SEMI[step]) % 12\n",
    "    # const mod = (n: number, m: number) => ((n % m) + m) % m;\n",
    "    mod = lambda n, m: ((n % m) + m ) % m\n",
    "    height = mod(SEMI[step] + alt, 12) - 12 * 99 if oct is None else SEMI[step] + alt + 12 * (oct + 1)\n",
    "\n",
    "    midi = height if 0 <= height <= 127 else None\n",
    "    freq = None if oct is None else pow(2, (height - 69) / 12) * 440\n",
    "\n",
    "    return acc, alt, chroma, coord, freq, height, letter, midi, name, oct, pc, step\n",
    "\n",
    "\n",
    "def get_note(name: str):\n",
    "    if isinstance(name, str):\n",
    "        parse(name)\n",
    "\n",
    "    else:\n",
    "        if name is pitch_name:\n",
    "            get_note(get_pitch(src))\n",
    "\n",
    "        else:\n",
    "            if name is named:\n",
    "                note(src.name)\n",
    "\n",
    "            else:\n",
    "                no_note\n",
    "    return ''\n",
    "\n",
    "\n",
    "def tokeniz_key(name):\n",
    "    if not isinstance(name, str):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    frags = name.split(' ')\n",
    "    tonic = get_note(frags[0].lower())\n",
    "    if tonic is None:\n",
    "        n = get_note(name)\n",
    "        return \"\", name if n is None else n, \"\"\n",
    "\n",
    "    tp = name.lower()[: len(tonic)+1]\n",
    "    return tonic, tp if len(tp) else \"\"\n",
    "\n",
    "\n",
    "def get_scale_type():\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_interval():\n",
    "    pass\n",
    "\n",
    "\n",
    "def coord2note():\n",
    "    pass\n",
    "\n",
    "\n",
    "def transpose(note_name, interval_name):\n",
    "    note = get_note(note_name)\n",
    "    interval = get_interval(interval_name)\n",
    "\n",
    "    if note is None or interval is None:\n",
    "        return \"\"\n",
    "\n",
    "    note_coord = note.coord\n",
    "    interval_coord = interval.coord\n",
    "    tr = [note_coord[0] + interval_coord[0]] if len(note_coord) == 1 else [note_coord[0] + interval_coord[0], note_coord[1] + interval_coord[1]]\n",
    "    return coord2note(tr).name\n",
    "\n",
    "\n",
    "    \n",
    "def get_scale(scale_name: str):\n",
    "    tokens = tokeniz_key(scale_name)\n",
    "    tonic = get_note(tokens[0])[8]\n",
    "    st = get_scale_type(tokens[1])\n",
    "\n",
    "    if st is None:\n",
    "        return None\n",
    "\n",
    "    tp = st.name\n",
    "    notes = map(st.intervals, lambda x: transpose(tonic, x)) if tonic is not None else []\n",
    "    \n",
    "\n",
    "\n",
    "def get_tonic_by_key(src: str):\n",
    "    return get_scale('C chromatic').notes[key - 1]\n",
    "    \n",
    "\n",
    "\n",
    "bpm = params['bpm'] // 5 * 5\n",
    "bpm = min(max(bpm, 70), 100)\n",
    "tonic = ''\n",
    "\n",
    "key = params['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "website = 'https://www.hooktheory.com'\n",
    "base_url = website + '/theorytab/artists/'\n",
    "sleep_time = 0.11\n",
    "# alphabet_list = string.ascii_lowercase\n",
    "alphabet_list = 'x'\n",
    "root_dir = '../datasets'\n",
    "root_xml = '../datasets/xml'\n",
    "\n",
    "\n",
    "def song_retrieval(artist, song, path_song):\n",
    "\n",
    "    suffix = '/theorytab/view/' + artist + '/' + song\n",
    "    song_url = song_url = 'https://www.hooktheory.com' + suffix\n",
    "    response_song = requests.get(song_url)\n",
    "\n",
    "    soup = BeautifulSoup(response_song.text, 'html.parser')\n",
    "\n",
    "    section_list = [item['href'].split('#')[-1] for item in soup.find_all('a', {'href': re.compile(suffix+'#')})]\n",
    "    pk_list = [item['href'].split('/')[-1] for item in soup.find_all('a', {'href': re.compile(\"/theorytab/chords/pk/\")})]\n",
    "\n",
    "    # save xml\n",
    "    for idx, pk in enumerate(pk_list):\n",
    "        req_url = 'https://www.hooktheory.com/songs/getXmlByPk?pk=' + str(pk)\n",
    "        response_info = requests.get(req_url)\n",
    "        content = response_info.text\n",
    "\n",
    "        with open(os.path.join(path_song, section_list[idx] + \".xml\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "        time.sleep(0.08)\n",
    "\n",
    "    # get genre\n",
    "    wikiid = soup.findAll(\"multiselect\", {\"items\": \"genres\"})[0]['wikiid']\n",
    "    response_genre = requests.get('https://www.hooktheory.com/wiki/' + str(wikiid) + '/genres')\n",
    "    genre_act_list = json.loads(response_genre.text)\n",
    "    genres = []\n",
    "    for g in genre_act_list:\n",
    "        if g['active']:\n",
    "            genres.append(g['name'])\n",
    "\n",
    "    # saving\n",
    "    info = {'section': section_list, 'pk': pk_list, 'song_url': song_url,\n",
    "            'genres': genres, 'wikiid': wikiid}\n",
    "\n",
    "    with open(os.path.join(path_song, 'song_info.json'), \"w\") as f:\n",
    "        json.dump(info, f)\n",
    "\n",
    "\n",
    "def get_song_list(url_artist, quite=False):\n",
    "    response_tmp = requests.get(website + url_artist)\n",
    "    soup = BeautifulSoup(response_tmp.text, 'html.parser')\n",
    "    item_list = soup.find_all(\"li\", {\"class\": re.compile(\"overlay-trigger\")})\n",
    "\n",
    "    song_name_list = []\n",
    "    for item in item_list:\n",
    "        song_name = item.find_all(\"a\", {\"class\": \"a-no-decoration\"})[0]['href'].split('/')[-1]\n",
    "        song_name_list.append(song_name)\n",
    "        if not quite:\n",
    "            print('   > %s' % song_name)\n",
    "    return song_name_list\n",
    "\n",
    "\n",
    "def traverse_website():\n",
    "    '''\n",
    "    Retrieve all urls of artists and songs from the website\n",
    "    '''\n",
    "\n",
    "    list_pages = []\n",
    "    archive_artist = dict()\n",
    "    artist_count = 0\n",
    "    song_count = 0\n",
    "\n",
    "    for ch in alphabet_list:\n",
    "        time.sleep(sleep_time)\n",
    "        url = base_url + ch\n",
    "        response_tmp = requests.get(url)\n",
    "        soup = BeautifulSoup(response_tmp.text, 'html.parser')\n",
    "        page_count = 0\n",
    "\n",
    "        print('==[%c]=================================================' % ch)\n",
    "\n",
    "        # get artists list by pages\n",
    "        url_artist_list = []\n",
    "        for page in range(1, 9999):\n",
    "            url = 'https://www.hooktheory.com/theorytab/artists/'+ch+'?page=' + str(page)\n",
    "            print(url)\n",
    "            time.sleep(sleep_time)\n",
    "            response_tmp = requests.get(url)\n",
    "            soup = BeautifulSoup(response_tmp.text, 'html.parser')\n",
    "            item_list = soup.find_all(\"li\", {\"class\": re.compile(\"overlay-trigger\")})\n",
    "\n",
    "            if item_list:\n",
    "                page_count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            for item in item_list:\n",
    "                url_artist_list.append(item.find_all(\"a\", {\"class\": \"a-no-decoration\"})[0]['href'])\n",
    "\n",
    "        print('Total:', len(url_artist_list))\n",
    "\n",
    "        print('----')\n",
    "\n",
    "        if not page_count:\n",
    "            page_count = 1\n",
    "\n",
    "        # get song of artists\n",
    "        artist_song_dict = dict()\n",
    "\n",
    "        for url_artist in url_artist_list:\n",
    "            artist_count += 1\n",
    "            time.sleep(sleep_time)\n",
    "            artist_name = url_artist.split('/')[-1]\n",
    "            print(artist_name)\n",
    "            song_name_list = get_song_list(url_artist)\n",
    "            song_count += len(song_name_list)\n",
    "            artist_song_dict[artist_name] = song_name_list\n",
    "\n",
    "        archive_artist[ch] = artist_song_dict\n",
    "        list_pages.append(page_count)\n",
    "\n",
    "    print('=======================================================')\n",
    "    print(list_pages)\n",
    "    print('Artists:', artist_count)\n",
    "    print('Songs:', song_count)\n",
    "\n",
    "    archive_artist['num_song'] = song_count\n",
    "    archive_artist['num_artist'] = artist_count\n",
    "\n",
    "    return archive_artist\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    archive_artist = traverse_website()\n",
    "\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "\n",
    "    if not os.path.exists(root_xml):\n",
    "        os.makedirs(root_xml)\n",
    "\n",
    "    path_artists = os.path.join(root_dir, 'archive_artist.json')\n",
    "    with open(path_artists, \"w\") as f:\n",
    "        json.dump(archive_artist, f)\n",
    "\n",
    "    with open(path_artists, \"r\") as f:\n",
    "        archive_artist = json.load(f)\n",
    "\n",
    "    count_ok = 0\n",
    "    song_count = archive_artist['num_song']\n",
    "\n",
    "    for ch in alphabet_list:\n",
    "        path_ch = os.path.join(root_xml, ch)\n",
    "        print('==[%c]=================================================' % ch)\n",
    "        \n",
    "        if not os.path.exists(path_ch):\n",
    "            os.makedirs(path_ch)\n",
    "\n",
    "        for a_name in archive_artist[ch].keys():\n",
    "            for s_name in archive_artist[ch][a_name]:\n",
    "\n",
    "                try:\n",
    "                    print('(%3d/%3d) %s   %s' % (count_ok, song_count, a_name, s_name))\n",
    "                    path_song = os.path.join(path_ch, a_name, s_name)\n",
    "\n",
    "                    if not os.path.exists(path_song):\n",
    "                        os.makedirs(path_song)\n",
    "\n",
    "                    time.sleep(sleep_time)\n",
    "                    song_retrieval(a_name, s_name, path_song)\n",
    "\n",
    "                    count_ok += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "    print('total:', count_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hooktheory.com/theorytab/genres/alt-country?page=2 not found\n",
      "1 pages found for alt-country\n",
      " getting 78 for alt-country\n",
      "https://www.hooktheory.com/theorytab/genres/alternative?page=7 not found\n",
      "6 pages found for alternative\n",
      " getting 600 for alternative\n",
      "https://www.hooktheory.com/theorytab/genres/blues?page=3 not found\n",
      "2 pages found for blues\n",
      " getting 163 for blues\n",
      "https://www.hooktheory.com/theorytab/genres/childrens?page=3 not found\n",
      "2 pages found for childrens\n",
      " getting 126 for childrens\n",
      "https://www.hooktheory.com/theorytab/genres/classical?page=5 not found\n",
      "4 pages found for classical\n",
      " getting 337 for classical\n",
      "https://www.hooktheory.com/theorytab/genres/country?page=4 not found\n",
      "3 pages found for country\n",
      " getting 213 for country\n",
      "https://www.hooktheory.com/theorytab/genres/dance?page=7 not found\n",
      "6 pages found for dance\n",
      " getting 600 for dance\n",
      "https://www.hooktheory.com/theorytab/genres/disney?page=3 not found\n",
      "2 pages found for disney\n",
      " getting 119 for disney\n",
      "https://www.hooktheory.com/theorytab/genres/electronic?page=7 not found\n",
      "6 pages found for electronic\n",
      " getting 600 for electronic\n",
      "https://www.hooktheory.com/theorytab/genres/experimental?page=5 not found\n",
      "4 pages found for experimental\n",
      " getting 391 for experimental\n",
      "https://www.hooktheory.com/theorytab/genres/folk?page=5 not found\n",
      "4 pages found for folk\n",
      " getting 315 for folk\n",
      "https://www.hooktheory.com/theorytab/genres/hip-hop-rap?page=7 not found\n",
      "6 pages found for hip-hop-rap\n",
      " getting 569 for hip-hop-rap\n",
      "https://www.hooktheory.com/theorytab/genres/holiday?page=2 not found\n",
      "1 pages found for holiday\n",
      " getting 58 for holiday\n",
      "https://www.hooktheory.com/theorytab/genres/house?page=6 not found\n",
      "5 pages found for house\n",
      " getting 409 for house\n",
      "https://www.hooktheory.com/theorytab/genres/indie?page=7 not found\n",
      "6 pages found for indie\n",
      " getting 600 for indie\n",
      "https://www.hooktheory.com/theorytab/genres/j-pop?page=6 not found\n",
      "5 pages found for j-pop\n",
      " getting 475 for j-pop\n",
      "https://www.hooktheory.com/theorytab/genres/jazz?page=6 not found\n",
      "5 pages found for jazz\n",
      " getting 405 for jazz\n",
      "https://www.hooktheory.com/theorytab/genres/k-pop?page=3 not found\n",
      "2 pages found for k-pop\n",
      " getting 191 for k-pop\n",
      "https://www.hooktheory.com/theorytab/genres/latin?page=4 not found\n",
      "3 pages found for latin\n",
      " getting 292 for latin\n",
      "https://www.hooktheory.com/theorytab/genres/metal?page=3 not found\n",
      "2 pages found for metal\n",
      " getting 141 for metal\n",
      "https://www.hooktheory.com/theorytab/genres/pop?page=7 not found\n",
      "6 pages found for pop\n",
      " getting 600 for pop\n",
      "https://www.hooktheory.com/theorytab/genres/punk?page=3 not found\n",
      "2 pages found for punk\n",
      " getting 145 for punk\n",
      "https://www.hooktheory.com/theorytab/genres/r-and-b?page=7 not found\n",
      "6 pages found for r-and-b\n",
      " getting 544 for r-and-b\n",
      "https://www.hooktheory.com/theorytab/genres/reggae?page=2 not found\n",
      "1 pages found for reggae\n",
      " getting 80 for reggae\n",
      "https://www.hooktheory.com/theorytab/genres/rock?page=7 not found\n",
      "6 pages found for rock\n",
      " getting 600 for rock\n",
      "https://www.hooktheory.com/theorytab/genres/singer-songwriter?page=5 not found\n",
      "4 pages found for singer-songwriter\n",
      " getting 333 for singer-songwriter\n",
      "https://www.hooktheory.com/theorytab/genres/soul?page=4 not found\n",
      "3 pages found for soul\n",
      " getting 280 for soul\n",
      "https://www.hooktheory.com/theorytab/genres/soundtrack?page=7 not found\n",
      "6 pages found for soundtrack\n",
      " getting 600 for soundtrack\n",
      "https://www.hooktheory.com/theorytab/genres/techno?page=3 not found\n",
      "2 pages found for techno\n",
      " getting 107 for techno\n",
      "https://www.hooktheory.com/theorytab/genres/video-game?page=7 not found\n",
      "6 pages found for video-game\n",
      " getting 600 for video-game\n",
      "https://www.hooktheory.com/theorytab/genres/vocal?page=2 not found\n",
      "1 pages found for vocal\n",
      " getting 97 for vocal\n",
      "https://www.hooktheory.com/theorytab/genres/world?page=3 not found\n",
      "2 pages found for world\n",
      " getting 101 for world\n",
      "https://www.hooktheory.com/theorytab/genres/worship?page=2 not found\n",
      "1 pages found for worship\n",
      " getting 67 for worship\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "GENRES_BASE_URL = 'https://www.hooktheory.com/theorytab/genres'\n",
    "genres = \"Alt-Country, Alternative, Blues, Childrens, Classical, Country, Dance, Disney, Electronic, Experimental, Folk, Hip-Hop-Rap, Holiday, House, Indie, J-Pop, Jazz, K-pop, Latin, Metal, Pop, Punk, R-and-B, Reggae, Rock, Singer-Songwriter, Soul, Soundtrack, Techno, Video-Game, Vocal, World, Worship\".lower().strip().replace(' ','').split(',')\n",
    "picked_set = {'blues', 'jazz', 'r-and-b', 'rock', 'hip-hop-rap', 'punk', 'metal'}\n",
    "\n",
    "# <p class=\"song\">Ghost Of Days Gone By</p><p class=\"artist\">\n",
    "pat = re.compile(r'<p class=\"song\">(?P<songs>.*?)</p><p class=\"artist\">by (?P<artist>.*?)</p>')\n",
    "\n",
    "genre2song_and_artist = {}\n",
    "pat = re.compile(r'<p class=\"song\">(?P<songs>.*?)</p><p class=\"artist\">by (?P<artist>.*?)</p>')\n",
    "\n",
    "for p in genres:\n",
    "    assert p in genres, p\n",
    "    song_and_artist = []\n",
    "    url = f\"{GENRES_BASE_URL}/{p}\"\n",
    "    urls = [url]\n",
    "    page_cnt = 1\n",
    "    resp = requests.get(url)\n",
    "    assert resp.status_code == 200, (p, url)\n",
    "    html = resp.text\n",
    "    while True:\n",
    "        page_cnt += 1\n",
    "        page_url = f\"{url}?page={page_cnt}\"\n",
    "        if page_url.split('/', 3)[-1] in html:\n",
    "            urls.append(page_url)\n",
    "        else:\n",
    "            print(f\"{page_url} not found\")\n",
    "            break\n",
    "\n",
    "    print(f\"{len(urls)} pages found for {p}\")\n",
    "\n",
    "    for l in urls:\n",
    "        resp = requests.get(l)\n",
    "        assert resp.status_code == 200, (p, url)\n",
    "        song_and_artist.extend(re.findall(pat, resp.text))    \n",
    "    genre2song_and_artist[p] = song_and_artist\n",
    "    print(f' getting {len(song_and_artist)} for {p}')\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10836\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cnt = 0\n",
    "for k, v in genre2song_and_artist.items():\n",
    "    cnt += len(v)\n",
    "print(cnt)\n",
    "\n",
    "json.dump(genre2song_and_artist, open('/workspace/model/dataset/genre2song.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17551\n",
      "9924\n",
      "alt-country: 58/78\n",
      "alternative: 264/600\n",
      "blues: 105/163\n",
      "childrens: 58/126\n",
      "classical: 92/337\n",
      "country: 111/213\n",
      "dance: 345/600\n",
      "disney: 56/119\n",
      "electronic: 340/600\n",
      "experimental: 143/391\n",
      "folk: 152/315\n",
      "hip-hop-rap: 300/569\n",
      "holiday: 37/58\n",
      "house: 266/409\n",
      "indie: 231/600\n",
      "j-pop: 176/475\n",
      "jazz: 176/405\n",
      "k-pop: 120/191\n",
      "latin: 55/292\n",
      "metal: 82/141\n",
      "pop: 300/600\n",
      "punk: 73/145\n",
      "r-and-b: 289/544\n",
      "reggae: 49/80\n",
      "rock: 334/600\n",
      "singer-songwriter: 163/333\n",
      "soul: 152/280\n",
      "soundtrack: 202/600\n",
      "techno: 52/107\n",
      "video-game: 145/600\n",
      "vocal: 47/97\n",
      "world: 31/101\n",
      "worship: 25/67\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "dfiles = list(glob(f\"/workspace/model/dataset/processed/*.json\"))\n",
    "print(len(dfiles))\n",
    "dsongs = set([f.split('/')[-1].split('.')[0].split('-')[1].lower().replace(' ', '') for f in dfiles])\n",
    "print(len(dsongs))\n",
    "for gnr, art_and_song in genre2song_and_artist.items():\n",
    "    cnt = 0\n",
    "    for s in art_and_song:\n",
    "        if s[0].lower().replace(' ', '') in dsongs:\n",
    "            cnt += 1\n",
    "\n",
    "    print(f\"{gnr}: {cnt}/{len(art_and_song)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
